{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdec0c5e-443c-4759-af66-3657473f063e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1. Contexto de Negócio:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad0bd7db-2c12-4f15-ba6f-86aa0f0640b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\"House Flipping\" é uma modalidade de investimento imobiliário, que compreende (i) a compra de imóveis descontados, (ii) reforma de custo reduzido com foco em valor de mercado, e (iii) posterior venda em curto espaço de tempo. Tradicionalmente esta operação é focada em imóveis residenciais.\n",
    "\n",
    "A grande ideia por trás desse investimento é adquirir imóveis bastante descontados quando o vendedor tem urgência no negócio (casos de dívidas, divórcio, falecimento, necessidade de liberar capital, etc), priorizando excelente localização. Para o contexto do \"House Flipping\", boa localização seria aquela que permitiria o giro rápido do imóvel, ou seja, bairros de alta liquidez. \n",
    "\n",
    "Seguindo o princípio da oferta e da procura, bairros de alta liquidez nos centros urbanos são, em geral, aqueles com maior preço por metro quadrado. Por este motivo, uma análise dos preços de venda de imóveis é um excelente ponto de partida para um investidor desse tipo selecionar sua área de atuação.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32c62eb4-ae43-4b14-819e-eeff7ee9ebc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2. Objetivo da análise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6034b23a-9352-4c59-b9af-3253581262aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O objetivo desta análise é fazer um panorama geral de preços de venda de imóveis residenciais na cidade de São Paulo. \n",
    "\n",
    "Para este intuito, serão analisados os dados de todas as transações imobiliárias para as quais houve recolhimento de ITBI (Imposto sobre a Transmissão de Bens Imóveis), no período de 2022 a 2025 nessa cidade.\n",
    "\n",
    "As principais perguntas que se propõe responder são:\n",
    "- Quais são os top 10 bairros de maior preço por metro quadrado na cidade de São Paulo?\n",
    "- Como tem sido a variação desses valores nos últimos 3 anos? Que bairros apresentam maior valorização?\n",
    "- Que características dos imóveis (tipologia, número de quartos, vaga de garagem, com/sem elevador, etc) estão relacionadas a maior valorização deles?\n",
    "- Existe sazonalidade no mercado imobiliário desta cidade? Quais são os meses mais indicados para compra descontada?\n",
    "- Como é a aceitação dos vendedores em relação a financiamento? Em média, qual percentual do valor de venda é financiado? \n",
    "\n",
    "Observação: Inicialmente o objetivo era estudar a cidade de Juiz de Fora - MG, onde resido. No entanto, tal objetivo não foi possível pela falta de disponibilidade de informações granulares no portal de dados de ITBI dessa cidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32340a1b-a105-4a7e-8c8e-8fb3f2b9fbf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 3. Busca e coleta de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97072ef2-b217-479c-80dc-e3349a145578",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.1 Fontes de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "505110a9-8ce5-45d9-91dd-db54ab5f6813",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.1.1 Dados ITBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47f31654-ca01-404b-9a9d-aeb0a58fb242",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A fonte dos dados de ITBI utilizados nesta análise é a Prefeitura de São Paulo, através do endereço: <https://prefeitura.sp.gov.br/web/fazenda/w/acesso_a_informacao/31501>\n",
    "\n",
    "**URL das bases de dados em formato xlsx:**\n",
    "\n",
    "2025: https://prefeitura.sp.gov.br/cidade/secretarias/upload/fazenda/arquivos/itbi/GUIAS%20DE%20ITBI%20PAGAS%20%2825112025%29.xlsx\n",
    "\n",
    "2024: https://prefeitura.sp.gov.br/cidade/secretarias/upload/fazenda/arquivos/itbi/GUIAS-DE-ITBI-PAGAS-2024.xlsx\n",
    "\n",
    "2023: https://www.prefeitura.sp.gov.br/cidade/secretarias/upload/fazenda/arquivos/XLSX/GUIAS-DE-ITBI-PAGAS-2023.xlsx\n",
    "\n",
    "2022: https://www.prefeitura.sp.gov.br/cidade/secretarias/upload/fazenda/arquivos/XLSX/GUIAS_DE_ITBI_PAGAS_12-2022.xlsx \n",
    "\n",
    "Cada uma das URLs acima descritas apresenta os dados de um ano calendário. Dentro do arquivo xlsx os dados de cada um dos meses são reportados em abas diferentes. Para o ano de 2025 estão disponíveis dados até o mês de outubro.\n",
    "\n",
    "As últimas abas dos arquivos contém informações complementares que serão utilizadas no glossário de dados e nas tabelas dimensão que serão descritas no capítulo de modelagem. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5587d052-d499-4699-b083-ac6ce41bd388",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.1.2 Dados de CEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18a26d76-6239-472c-982d-7201de654d43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As informações a respeito dos CEPs foram obtidas no site CEP Aberto, disponível em: https://www.cepaberto.com/downloads/new\n",
    "\n",
    "Cidades e Municípios: https://www.cepaberto.com/downloads.csv?name=cities\n",
    "\n",
    "Estados: https://www.cepaberto.com/downloads.csv?name=states\n",
    "\n",
    "\n",
    "CEPs do estado de São Paulo:\n",
    "\n",
    "https://www.cepaberto.com/downloads.csv?name=SP&part=1\n",
    "\n",
    "https://www.cepaberto.com/downloads.csv?name=SP&part=2\n",
    "\n",
    "https://www.cepaberto.com/downloads.csv?name=SP&part=3\n",
    "\n",
    "https://www.cepaberto.com/downloads.csv?name=SP&part=4\n",
    "\n",
    "https://www.cepaberto.com/downloads.csv?name=SP&part=5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "870849c0-b55f-4860-a88f-f38fdceeff2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O armazenamento dessas bases em nuvem está descrito nos scripts abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "972f60a2-87ff-4c10-bc6f-9213e1fc4d7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.2 Ingestão de dados e criação de tabelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64f45be6-9bb7-48d9-8025-53d312896bee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.2.1 Tabela consolidada com dados de ITBI (2022 a 2025):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "09fe130e-5932-41c5-a2bd-971103ec272f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Instalar biblioteca openpyxl para ler arquivo em formato xlsx\n",
    " \n",
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb35322a-6732-45b2-911b-0b1b20c83499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Reinicia o ambiente Python para garantir que a biblioteca esteja disponível\n",
    "\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a1e1dd22-e05c-47d9-b41c-c36a23f5f4e0",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764825021481}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cria tabela com dados de ITBI 2025\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "url = (\n",
    "    'https://prefeitura.sp.gov.br/cidade/secretarias/upload/fazenda/arquivos/itbi/'\n",
    "    'GUIAS%20DE%20ITBI%20PAGAS%20%2825112025%29.xlsx'\n",
    ")\n",
    "\n",
    "# Baixa o arquivo da url e salva em um arquivo temporário no cluster\n",
    "response = requests.get(url)\n",
    "with open('/tmp/seuarquivo.xlsx', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Lê as 10 primeiras abas do arquivo Excel (jan a out) para gerar um dicionário Python (chave - valor), contendo nome da aba e conteúdo gravado em um dataframe\n",
    "sheets = pd.read_excel(\n",
    "    '/tmp/seuarquivo.xlsx',\n",
    "    sheet_name=list(range(10))\n",
    ")\n",
    "\n",
    "# Seleciona apenas as 28 primeiras colunas de cada aba (dados para além dessas são lixo) e guarda em uma lista de dataframes\n",
    "dfs = [df.iloc[:, :28].copy() for df in sheets.values()]\n",
    "\n",
    "# Copia o header do primeiro df em todos os demais para conseguir concatená-los (dados originais tem headers despadronizados)\n",
    "columns = dfs[0].columns.tolist()\n",
    "for df in dfs:\n",
    "    df.columns = columns\n",
    "pdf_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Converte todas as colunas que contêm texto para tipo de dado string\n",
    "for col in pdf_all.select_dtypes(include=['object']).columns:\n",
    "    pdf_all[col] = pdf_all[col].astype(str)\n",
    "\n",
    "#Define função que limpa os nomes das colunas: tira espaços e caracteres especiais\n",
    "def clean_column(name):\n",
    "    return re.sub(r'[ ,;{}()\\n\\t=/\\.]', '_', str(name)).replace('°', 'o').replace('%', 'pct')\n",
    "\n",
    "#Chama a função clean_column definida anterioremente para limpar os nomes das colunas de pdf_all, em preparação para convertê-lo para DataFrame do Spark\n",
    "pdf_all.columns = [clean_column(col) for col in pdf_all.columns]\n",
    "\n",
    "# Converte o DataFrame do Pandas para um DataFrame do Spark\n",
    "df = spark.createDataFrame(pdf_all)\n",
    "\n",
    "# Deleta a tabela, caso já exista\n",
    "table_name = \"mvp_engdados_puc.bronze.guias_itbi_2025\"\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {table_name} PURGE\")\n",
    "\n",
    "# Conta número de linhas do DataFrame e mostra 100 linhas dele\n",
    "num_linhas = df.count()\n",
    "print(f\"Número de linhas no Spark: {num_linhas}\")\n",
    "display(df.limit(100))\n",
    "\n",
    "# Salva o DataFrame do Spark em uma tabela persistida no DBFS\n",
    "df.write.format(\"delta\").option(\"overwriteSchema\", \"true\").mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "# Os headers de cada aba do Excel original estão misturados no corpo dos dados. Esta limpeza será feita na etapa de qualidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4211cc07-4cc5-48f8-a688-98816ab672f7",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765065106531}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Processamento idem anterior para criar as tabelas de itbi pagos de 2022 a 20224\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "urls = [\n",
    "    'https://prefeitura.sp.gov.br/cidade/secretarias/upload/fazenda/arquivos/itbi/GUIAS-DE-ITBI-PAGAS-2024.xlsx',\n",
    "    'https://www.prefeitura.sp.gov.br/cidade/secretarias/upload/fazenda/arquivos/XLSX/GUIAS-DE-ITBI-PAGAS-2023.xlsx',\n",
    "    'https://www.prefeitura.sp.gov.br/cidade/secretarias/upload/fazenda/arquivos/XLSX/GUIAS_DE_ITBI_PAGAS_12-2022.xlsx',\n",
    "]\n",
    "\n",
    "#Define função que limpa os nomes das colunas: tira espaços e caracteres especiais\n",
    "def clean_column(name):\n",
    "    return re.sub(r'[ ,;{}()\\n\\t=/\\.]', '_', str(name)).replace('°', 'o').replace('%', 'pct')\n",
    "\n",
    "# Para os anos de 2022 a 2024:\n",
    "for idx, url in enumerate(urls, start=1):\n",
    "    \n",
    "    # Baixa o arquivo da url e salva em um arquivo temporário no cluster\n",
    "    response = requests.get(url)\n",
    "    file_path = f'/tmp/seuarquivo_{idx}.xlsx'\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # Lê as 12 primeiras abas do arquivo Excel (jan a dez)\n",
    "    sheets = pd.read_excel(\n",
    "        file_path,\n",
    "        sheet_name=list(range(12))\n",
    "    )\n",
    "\n",
    "    # Seleciona apenas as 28 primeiras colunas de cada aba (dados para além dessas são lixo)\n",
    "    dfs = [df.iloc[:, :28].copy() for df in sheets.values()]\n",
    "\n",
    "    # Copia um header selecionado padrão em todos os demais para conseguir concatená-los (dados originais tem headers despadronizados)\n",
    "    columns = dfs[1].columns.tolist()\n",
    "    for df in dfs:\n",
    "        df.columns = columns\n",
    "    pdf_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Converte todas as colunas que contêm texto para tipo de dado string\n",
    "    for col in pdf_all.select_dtypes(include=['object']).columns:\n",
    "        pdf_all[col] = pdf_all[col].astype(str)\n",
    "\n",
    "    #Chama a função clean_column definida anteriormente para limpar os nomes das colunas de pdf_all, em preparação para convertê-lo para DataFrame do Spark\n",
    "    pdf_all.columns = [clean_column(col) for col in pdf_all.columns]\n",
    "\n",
    "    # Converte o DataFrame do Pandas para um DataFrame do Spark\n",
    "    df = spark.createDataFrame(pdf_all)\n",
    "\n",
    "    # Deleta a tabela, caso já exista\n",
    "    table_name = f\"mvp_engdados_puc.bronze.guias_itbi_{idx}\"\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS {table_name} PURGE\")\n",
    "\n",
    "    # Conta número de linhas do DataFrame e mostra 100 linhas dele\n",
    "    num_linhas = df.count()\n",
    "    print(f\"Número de linhas no Spark: {num_linhas}\")\n",
    "    display(df.limit(100))\n",
    "\n",
    "    # Salva o DataFrame do Spark em uma tabela persistida no DBFS\n",
    "    df.write.format(\"delta\").option(\"overwriteSchema\", \"true\").mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "# Os headers de cada aba do Excel original estão misturados no corpo dos dados. Esta limpeza será feita na etapa de qualidade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "dc4c5292-a65f-474b-8d2b-9781f4bf63e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "/* Criação da tabela agregada contendo todos os dados de itbi desde 2022 */\n",
    "\n",
    "CREATE OR REPLACE TABLE mvp_engdados_puc.bronze.guias_itbi_bronze AS\n",
    "\n",
    "SELECT \n",
    "  try_cast(No_do_Cadastro__SQL_ AS BIGINT) AS No_do_Cadastro__SQL_,\n",
    "  Nome_do_Logradouro,\n",
    "  try_cast(`Número` AS BIGINT) AS `Número`,\n",
    "  Complemento,\n",
    "  Bairro,\n",
    "  `Referência`,\n",
    "  try_cast(CEP AS DOUBLE) AS CEP,\n",
    "  `Natureza_de_Transação`,\n",
    "  try_cast(`Valor_de_Transação__declarado_pelo_contribuinte_` AS DOUBLE) AS `Valor_de_Transação__declarado_pelo_contribuinte_`,\n",
    "  try_cast(`Data_de_Transação` AS DATE) AS `Data_de_Transação`,\n",
    "  try_cast(`Valor_Venal_de_Referência` AS DOUBLE) AS `Valor_Venal_de_Referência`,\n",
    "  try_cast(`Proporção_Transmitida__pct_` AS DOUBLE) AS `Proporção_Transmitida__pct_`,\n",
    "  try_cast(`Valor_Venal_de_Referência__proporcional_` AS DOUBLE) AS `Valor_Venal_de_Referência__proporcional_`,\n",
    "  try_cast(`Base_de_Cálculo_adotada` AS DOUBLE) AS `Base_de_Cálculo_adotada`,\n",
    "  Tipo_de_financiamento,\n",
    "  try_cast(Valor_Financiado AS DOUBLE) AS Valor_Financiado,\n",
    "  `Cartório_de_Registro`,\n",
    "  try_cast(`Matrícula_do_Imóvel` AS BIGINT) AS `Matrícula_do_Imóvel`,\n",
    "  `Situação_do_SQL`,\n",
    "  try_cast(`Área_do_Terreno__m2_` AS BIGINT) AS `Área_do_Terreno__m2_`,\n",
    "  try_cast(Testada__m_ AS BIGINT) AS Testada__m_,\n",
    "  try_cast(`Fração_Ideal` AS DOUBLE) AS `Fração_Ideal`,\n",
    "  try_cast(`Área_Construída__m2_` AS BIGINT) AS `Área_Construída__m2_`,\n",
    "  try_cast(Uso__IPTU_ AS BIGINT) AS Uso__IPTU_,\n",
    "  `Descrição_do_uso__IPTU_`,\n",
    "  try_cast(`Padrão__IPTU_` AS BIGINT) AS `Padrão__IPTU_`,\n",
    "  `Descrição_do_Padrão__IPTU_`,\n",
    "  try_cast(ACC__IPTU_ AS STRING) AS ACC__IPTU_\n",
    "  \n",
    "FROM mvp_engdados_puc.bronze.guias_itbi_2025\n",
    "\n",
    "UNION ALL\n",
    "SELECT \n",
    "try_cast(No_do_Cadastro__SQL_ AS BIGINT) AS No_do_Cadastro__SQL_,\n",
    "  Nome_do_Logradouro,\n",
    "  try_cast(`Número` AS BIGINT) AS `Número`,\n",
    "  Complemento,\n",
    "  Bairro,\n",
    "  `Referência`,\n",
    "  try_cast(CEP AS DOUBLE) AS CEP,\n",
    "  `Natureza_de_Transação`,\n",
    "  try_cast(`Valor_de_Transação__declarado_pelo_contribuinte_` AS DOUBLE) AS `Valor_de_Transação__declarado_pelo_contribuinte_`,\n",
    "  try_cast(`Data_de_Transação` AS DATE) AS `Data_de_Transação`,\n",
    "  try_cast(`Valor_Venal_de_Referência` AS DOUBLE) AS `Valor_Venal_de_Referência`,\n",
    "  try_cast(`Proporção_Transmitida__pct_` AS DOUBLE) AS `Proporção_Transmitida__pct_`,\n",
    "  try_cast(`Valor_Venal_de_Referência__proporcional_` AS DOUBLE) AS `Valor_Venal_de_Referência__proporcional_`,\n",
    "  try_cast(`Base_de_Cálculo_adotada` AS DOUBLE) AS `Base_de_Cálculo_adotada`,\n",
    "  Tipo_de_financiamento,\n",
    "  try_cast(Valor_Financiado AS DOUBLE) AS Valor_Financiado,\n",
    "  `Cartório_de_Registro`,\n",
    "  try_cast(`Matrícula_do_Imóvel` AS BIGINT) AS `Matrícula_do_Imóvel`,\n",
    "  `Situação_do_SQL`,\n",
    "  try_cast(`Área_do_Terreno__m2_` AS BIGINT) AS `Área_do_Terreno__m2_`,\n",
    "  try_cast(Testada__m_ AS BIGINT) AS Testada__m_,\n",
    "  try_cast(`Fração_Ideal` AS DOUBLE) AS `Fração_Ideal`,\n",
    "  try_cast(`Área_Construída__m2_` AS BIGINT) AS `Área_Construída__m2_`,\n",
    "  try_cast(Uso__IPTU_ AS BIGINT) AS Uso__IPTU_,\n",
    "  `Descrição_do_uso__IPTU_`,\n",
    "  try_cast(`Padrão__IPTU_` AS BIGINT) AS `Padrão__IPTU_`,\n",
    "  ACC__IPTU_ AS `Descrição_do_Padrão__IPTU_`, \n",
    "  try_cast(ACC__IPTU__1 AS STRING) AS ACC__IPTU_\n",
    "\n",
    "FROM mvp_engdados_puc.bronze.guias_itbi_1\n",
    "\n",
    "UNION ALL\n",
    "SELECT \n",
    "try_cast(No_do_Cadastro__SQL_ AS BIGINT) AS No_do_Cadastro__SQL_,\n",
    "  Nome_do_Logradouro,\n",
    "  try_cast(`Número` AS BIGINT) AS `Número`,\n",
    "  Complemento,\n",
    "  Bairro,\n",
    "  `Referência`,\n",
    "  try_cast(CEP AS DOUBLE) AS CEP,\n",
    "  `Natureza_de_Transação`,\n",
    "  try_cast(`Valor_de_Transação__declarado_pelo_contribuinte_` AS DOUBLE) AS `Valor_de_Transação__declarado_pelo_contribuinte_`,\n",
    "  try_cast(`Data_de_Transação` AS DATE) AS `Data_de_Transação`,\n",
    "  try_cast(`Valor_Venal_de_Referência` AS DOUBLE) AS `Valor_Venal_de_Referência`,\n",
    "  try_cast(`Proporção_Transmitida__pct_` AS DOUBLE) AS `Proporção_Transmitida__pct_`,\n",
    "  try_cast(`Valor_Venal_de_Referência__proporcional_` AS DOUBLE) AS `Valor_Venal_de_Referência__proporcional_`,\n",
    "  try_cast(`Base_de_Cálculo_adotada` AS DOUBLE) AS `Base_de_Cálculo_adotada`,\n",
    "  Tipo_de_financiamento,\n",
    "  try_cast(Valor_Financiado AS DOUBLE) AS Valor_Financiado,\n",
    "  `Cartório_de_Registro`,\n",
    "  try_cast(`Matrícula_do_Imóvel` AS BIGINT) AS `Matrícula_do_Imóvel`,\n",
    "  `Situação_do_SQL`,\n",
    "  try_cast(`Área_do_Terreno__m2_` AS BIGINT) AS `Área_do_Terreno__m2_`,\n",
    "  try_cast(Testada__m_ AS BIGINT) AS Testada__m_,\n",
    "  try_cast(`Fração_Ideal` AS DOUBLE) AS `Fração_Ideal`,\n",
    "  try_cast(`Área_Construída__m2_` AS BIGINT) AS `Área_Construída__m2_`,\n",
    "  try_cast(Uso__IPTU_ AS BIGINT) AS Uso__IPTU_,\n",
    "  `Descrição_do_uso__IPTU_`,\n",
    "  try_cast(`Padrão__IPTU_` AS BIGINT) AS `Padrão__IPTU_`,\n",
    "  `Descrição_do_Padrão__IPTU_`,\n",
    "  try_cast(ACC__IPTU_ AS STRING) AS ACC__IPTU_ \n",
    "\n",
    "FROM mvp_engdados_puc.bronze.guias_itbi_2\n",
    "\n",
    "UNION ALL\n",
    "SELECT \n",
    "try_cast(No_do_Cadastro__SQL_ AS BIGINT) AS No_do_Cadastro__SQL_,\n",
    "  Nome_do_Logradouro,\n",
    "  try_cast(`Número` AS BIGINT) AS `Número`,\n",
    "  Complemento,\n",
    "  Bairro,\n",
    "  `Referência`,\n",
    "  try_cast(CEP AS DOUBLE) AS CEP,\n",
    "  `Natureza_de_Transação`,\n",
    "  try_cast(`Valor_de_Transação__declarado_pelo_contribuinte_` AS DOUBLE) AS `Valor_de_Transação__declarado_pelo_contribuinte_`,\n",
    "  try_cast(`Data_de_Transação` AS DATE) AS `Data_de_Transação`,\n",
    "  try_cast(`Valor_Venal_de_Referência` AS DOUBLE) AS `Valor_Venal_de_Referência`,\n",
    "  try_cast(`Proporção_Transmitida__pct_` AS DOUBLE) AS `Proporção_Transmitida__pct_`,\n",
    "  try_cast(`Valor_Venal_de_Referência__proporcional_` AS DOUBLE) AS `Valor_Venal_de_Referência__proporcional_`,\n",
    "  try_cast(`Base_de_Cálculo_adotada` AS DOUBLE) AS `Base_de_Cálculo_adotada`,\n",
    "  Tipo_de_financiamento,\n",
    "  try_cast(Valor_Financiado AS DOUBLE) AS Valor_Financiado,\n",
    "  `Cartório_de_Registro`,\n",
    "  try_cast(`Matrícula_do_Imóvel` AS BIGINT) AS `Matrícula_do_Imóvel`,\n",
    "  `Situação_do_SQL`,\n",
    "  try_cast(`Área_do_Terreno__m2_` AS BIGINT) AS `Área_do_Terreno__m2_`,\n",
    "  try_cast(Testada__m_ AS BIGINT) AS Testada__m_,\n",
    "  try_cast(`Fração_Ideal` AS DOUBLE) AS `Fração_Ideal`,\n",
    "  try_cast(`Área_Construída__m2_` AS BIGINT) AS `Área_Construída__m2_`,\n",
    "  try_cast(Uso__IPTU_ AS BIGINT) AS Uso__IPTU_,\n",
    "  `Descrição_do_uso__IPTU_`,\n",
    "  try_cast(`Padrão__IPTU_` AS BIGINT) AS `Padrão__IPTU_`,\n",
    "  ACC__IPTU_ `Descrição_do_Padrão__IPTU_`,\n",
    "  try_cast(ACC__IPTU__1 AS STRING) AS ACC__IPTU_\n",
    "  \n",
    "FROM mvp_engdados_puc.bronze.guias_itbi_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7306d4ae-cc78-4f9c-864e-82a719cddc8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "/* Visualizacão da tabela criada */\n",
    "\n",
    "SELECT * FROM mvp_engdados_puc.bronze.guias_itbi_bronze\n",
    "LIMIT 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "83982a03-6bec-449d-be96-3d2b49cd3fad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "/* Contador do número de linhas da tabela de itbi, camada bronze */\n",
    "SELECT COUNT(*) FROM mvp_engdados_puc.bronze.guias_itbi_bronze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17c6d581-c32a-4fb8-95c7-61d549022bdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.2.2 Tabela de dados de Uso do imóvel segundo o IPTU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "45afb692-4eac-443a-8f11-47af7ba6d0f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cria tabela com dados da dimensão Uso do IPTU\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "url = (\n",
    "    'https://prefeitura.sp.gov.br/cidade/secretarias/upload/fazenda/arquivos/itbi/'\n",
    "    'GUIAS%20DE%20ITBI%20PAGAS%20%2825112025%29.xlsx'\n",
    ")\n",
    "\n",
    "# Baixa o arquivo da url e salva em um arquivo temporário no cluster\n",
    "response = requests.get(url)\n",
    "with open('/tmp/seuarquivo.xlsx', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Lê apenas a aba chamada \"Tabela de USOS\"\n",
    "df_usos = pd.read_excel(\n",
    "    '/tmp/seuarquivo.xlsx',\n",
    "    sheet_name=\"Tabela de USOS\"\n",
    ")\n",
    "\n",
    "# Seleciona apenas as 2 primeiras colunas, pois se existirem mais colunas são lixo\n",
    "df_usos = df_usos.iloc[:, :2].copy()\n",
    "\n",
    "# Converte todas as colunas que contêm texto para tipo de dado string\n",
    "for col in df_usos.select_dtypes(include=['object']).columns:\n",
    "    df_usos[col] = df_usos[col].astype(str)\n",
    "\n",
    "# Converte o DataFrame do Pandas para um DataFrame do Spark\n",
    "df_spark_usos = spark.createDataFrame(df_usos)\n",
    "\n",
    "# Deleta a tabela, caso já exista\n",
    "table_name_usos = \"mvp_engdados_puc.bronze.tabela_dim_usos\"\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {table_name_usos} PURGE\")\n",
    "\n",
    "# Conta número de linhas do DataFrame e mostra no máximo 100 linhas dele\n",
    "num_linhas_usos = df_spark_usos.count()\n",
    "print(f\"Número de linhas no Spark: {num_linhas_usos}\")\n",
    "display(df_spark_usos.limit(100))\n",
    "\n",
    "# Salva o DataFrame do Spark em uma tabela persistida no DBFS\n",
    "df_spark_usos.write.format(\"delta\").option(\"overwriteSchema\", \"true\").mode(\"overwrite\").saveAsTable(table_name_usos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d6e23de6-6048-4ba7-a3a5-ab1e7728e695",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "/* Visualizacão da tabela criada */\n",
    "\n",
    "SELECT * FROM mvp_engdados_puc.bronze.tabela_dim_usos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7c2b70f-29eb-4b55-82a0-030732b86a77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.2.3 Tabela com dados dos CEPs de São Paulo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a15cd0aa-b36c-4510-b423-085beebb55df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A ingestão dos dados de CEP foi feita manualmente pelo Unit Catalog. Evidências abaixo:\n",
    "\n",
    "![](/Workspace/Users/izabelagreg@gmail.com/mvp-puc-eng-dados/Figuras/Ingestao_UnitCatalog_1)\n",
    "\n",
    "![](/Workspace/Users/izabelagreg@gmail.com/mvp-puc-eng-dados/Figuras/Ingestao_UnitCatalog_2)\n",
    "\n",
    "![](/Workspace/Users/izabelagreg@gmail.com/mvp-puc-eng-dados/Figuras/Ingestao_UnitCatalog_3)\n",
    "\n",
    "![](/Workspace/Users/izabelagreg@gmail.com/mvp-puc-eng-dados/Figuras/Ingestao_UnitCatalog_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9eb1c400-6527-46ba-9f69-1cd8ce9d3d9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Criação da tabela com todos os CEPs do estado de São Paulo\n",
    "import zipfile\n",
    "from functools import reduce\n",
    "\n",
    "zip_paths = [\n",
    "    \"/Volumes/mvp_engdados_puc/staging/bases_cep_sp/sp.cepaberto_parte_1.zip\",\n",
    "    \"/Volumes/mvp_engdados_puc/staging/bases_cep_sp/sp.cepaberto_parte_2.zip\",\n",
    "    \"/Volumes/mvp_engdados_puc/staging/bases_cep_sp/sp.cepaberto_parte_3.zip\",\n",
    "    \"/Volumes/mvp_engdados_puc/staging/bases_cep_sp/sp.cepaberto_parte_4.zip\",\n",
    "    \"/Volumes/mvp_engdados_puc/staging/bases_cep_sp/sp.cepaberto_parte_5.zip\"\n",
    "]\n",
    "staging_dir = \"/Volumes/mvp_engdados_puc/staging/bases_cep_sp\"\n",
    "\n",
    "csv_paths = []\n",
    "# Para cada um dos arquivos zip salvos em staging_dir, extrai o único arquivo CSV que ele contém e salva em csv_paths\n",
    "for zip_path in zip_paths:    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as arquivo_zip:\n",
    "        nome_do_csv = arquivo_zip.namelist()[0]\n",
    "        arquivo_zip.extract(nome_do_csv, staging_dir)\n",
    "        csv_paths.append(f\"{staging_dir}/{nome_do_csv}\")\n",
    "\n",
    "# Header para os CSVs\n",
    "colunas_cep = [\"cep\", \"logradouro\", \"descricao\", \"bairro\", \"cidade\", \"uf\"]\n",
    "\n",
    "# Lê cada um dos CSV, que não tem header, forçando o esquema indicado em colunas_cep\n",
    "df_list = [\n",
    "    spark.read.csv(\n",
    "        path,\n",
    "        sep=\",\",\n",
    "        header=False,\n",
    "        inferSchema=False\n",
    "    ).toDF(*colunas_cep)\n",
    "    for path in csv_paths\n",
    "]\n",
    "\n",
    "# Lê a lista de dataframes armazenados em df_list e une todos em um só\n",
    "df_cep_unido = reduce(lambda df1, df2: df1.unionByName(df2), df_list)\n",
    "\n",
    "# Deleta a tabela, caso já exista\n",
    "table_name_cep = \"mvp_engdados_puc.bronze.cepaberto_SP\"\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {table_name_cep} PURGE\")\n",
    "\n",
    "# Salva o DataFrame do Spark em uma tabela Delta persistida no DBFS\n",
    "df_cep_unido.write.format(\"delta\").option(\"overwriteSchema\", \"true\").mode(\"overwrite\").saveAsTable(table_name_cep)\n",
    "\n",
    "# Comando para ler 100 linhas da tabela Delta criada\n",
    "display(spark.table(table_name_cep).limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4de04a71-6803-40ac-b59d-c2097f36878d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Criação da tabela de códigos das cidades (base CEP)\n",
    "import zipfile\n",
    "\n",
    "zip_path = \"/Volumes/mvp_engdados_puc/staging/bases_cep_sp/cidades.cepaberto.zip\"\n",
    "staging_dir = \"/Volumes/mvp_engdados_puc/staging/bases_cep_sp\"\n",
    "\n",
    "# Extrai o único arquivo CSV contido no zip_path e salva no diretório\n",
    "with zipfile.ZipFile(zip_path, 'r') as arquivo_zip:\n",
    "    nome_do_csv = arquivo_zip.namelist()[0]\n",
    "    arquivo_zip.extract(nome_do_csv, staging_dir)\n",
    "    csv_path = f\"{staging_dir}/{nome_do_csv}\"\n",
    "\n",
    "# Header para o CSV\n",
    "colunas_cidades = [\"codigo_cidade\", \"nome_cidade\", \"codigo_estado\"]\n",
    "\n",
    "# Lê o CSV, que não tem header, forçando o esquema indicado em colunas_cidades\n",
    "df_cidades = spark.read.csv(\n",
    "    csv_path,\n",
    "    sep=\",\",\n",
    "    header=False,\n",
    "    inferSchema=False\n",
    ").toDF(*colunas_cidades)\n",
    "\n",
    "# Deleta a tabela, caso já exista\n",
    "table_name = \"mvp_engdados_puc.bronze.cepaberto_cidades\"\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {table_name} PURGE\")\n",
    "\n",
    "# Salva o DataFrame do Spark em uma tabela Delta persistida no DBFS\n",
    "df_cidades.write.format(\"delta\").option(\"overwriteSchema\", \"true\").mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "# Comando para ler 100 linhas da tabela Delta criada\n",
    "display(spark.table(table_name).limit(100))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "6c8723b3-2fb6-4ef7-bec2-0d69a44fc637",
     "origId": 5784499604213264,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7308278753137412,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "20251201_MVP_EngDados_parte1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
