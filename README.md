# mvp-puc-eng-dados
Reposit√≥rio para documenta√ß√£o do MVP produzido na Sprint de Engenharia de Dados, parte da p√≥s gradua√ß√£o em Ci√™ncia de Dados e Analytics da PUC-RJ.

# An√°lise de Mercado Imobili√°rio Residencial em S√£o Paulo: Estrat√©gia House Flipping

‚Äî Documenta√ß√£o e resumo gerado com aux√≠lio do Gemini (LLM).

---

## ‚ú® 1. Vis√£o Geral

Este reposit√≥rio cont√©m o projeto de Engenharia de Dados e a an√°lise completa do mercado de im√≥veis residenciais na cidade de S√£o Paulo. O objetivo √© fornecer um panorama de pre√ßos e valoriza√ß√£o para orientar a estrat√©gia de **"House Flipping"** (compra, reforma e revenda r√°pida de im√≥veis com desconto).

O trabalho envolveu a ingest√£o de grandes volumes de dados p√∫blicos, a aplica√ß√£o de t√©cnicas de qualidade de dados (**Delta Lake/Spark**) e a constru√ß√£o de um modelo de dados otimizado para an√°lise.

## üöÄ 2. Resultados Chave e Descobertas

O estudo focado em transa√ß√µes de compra e venda de im√≥veis residenciais (Jan/2022 a Out/2025) revelou os seguintes *insights* cr√≠ticos para investidores:

* **Top 10 Bairros de Alta Liquidez:** Os bairros mais caros e, presumivelmente, de maior liquidez (acima de 30 transa√ß√µes/ano) s√£o dominados pela regi√£o Oeste de S√£o Paulo, incluindo Jardim Am√©rica, Jardim Paulistano, Jardim Europa, Itaim Bibi e Cidade Jardim.
* **Maior Valoriza√ß√£o:** O bairro Cidade Jardim apresentou a maior valoriza√ß√£o no pre√ßo do metro quadrado, com um aumento de **97,6%** no per√≠odo de 2022 a 2025.
* **Tend√™ncia e Sazonalidade:** O mercado imobili√°rio em S√£o Paulo apresenta uma valoriza√ß√£o constante do pre√ßo m√©dio do metro quadrado (aumento de **20,2%** de Jan/22 a Out/25, com R2 de 0.922 na tend√™ncia), sem sazonalidade definida que justifique esperar por um "melhor momento" de compra.
* **Prefer√™ncia de Pagamento:** A maioria das transa√ß√µes (cerca de **63,5%**) √© realizada sem financiamento imobili√°rio. Isso sugere que propostas de compra √† vista t√™m um peso competitivo significativo para conseguir descontos.
* **Limita√ß√£o da An√°lise:** N√£o foi poss√≠vel correlacionar a valoriza√ß√£o com caracter√≠sticas granulares dos im√≥veis (quartos, vagas, elevador), devido √† indisponibilidade dessas informa√ß√µes em dados p√∫blicos de ITBI.

## ‚öôÔ∏è 3. Metodologia e Tecnologias

O projeto seguiu a **arquitetura de Data Lakehouse**, utilizando o padr√£o **Medallion**, com camadas Bronze (dados brutos), Prata (dados tratados) e Ouro (dados agregados para an√°lise).

| √Årea | Ferramentas e Tecnologias | Detalhes T√©cnicos |
| :--- | :--- | :--- |
| **Plataforma** | Databricks (Ambiente principal) | Uso de Notebooks para desenvolvimento, execu√ß√£o e visualiza√ß√£o. |
| **Linguagem** | Python e Spark SQL | Python (requests, pandas, openpyxl) para ingest√£o e Spark SQL para transforma√ß√µes (`CREATE TABLE AS`, `JOINs`). |
| **Fontes de Dados** | ITBI (Prefeitura de SP) e CEP Aberto | Ingest√£o e consolida√ß√£o de 4 arquivos .xlsx do ITBI (2022 a 2025) e dados de CEP em formato CSV. |
| **Modelagem** | Esquema Estrela (Prata) e Flat (Ouro) | Cria√ß√£o de tabelas Fato (`guias_itbi_prata`) e Dimens√µes (`cep_sp_capital`, `tabela_dim_usos`). E cria√ß√£o de uma tabela Flat (`guias_itbi_ouro`). |
| **Qualidade de Dados** | Testes de Unicidade, Integridade, Validade e Consist√™ncia | Tratamento de valores nulos, *outliers* de √°rea, padroniza√ß√£o de percentuais, exclus√£o de valores n√£o v√°lidos e filtragem de transa√ß√µes fora do escopo. |

## üìÇ 4. Estrutura do Reposit√≥rio

O projeto est√° dividido em tr√™s *notebooks*, que seguem a jornada da Engenharia de Dados e An√°lise:

* **20251201_MVP_EngDados_parte1.ipynb:** Contexto de Neg√≥cio, Objetivos e Ingest√£o de Dados (Cria√ß√£o da Camada Bronze).
* **20251201_MVP_EngDados_parte2.ipynb:** Modelagem, Qualidade e Transforma√ß√£o de Dados (Cria√ß√£o das Camadas Prata e Ouro).
* **20251201_MVP_EngDados_parte3.ipynb:** An√°lise Explorat√≥ria e Conclus√µes Finais (Resposta √†s Perguntas de Neg√≥cio e Visualiza√ß√µes).

## üõ†Ô∏è 5. Como Executar (Pr√©-requisitos)

Para reproduzir este projeto, voc√™ precisar√° de um ambiente que suporte o processamento distribu√≠do de dados:

* **Plataforma Databricks:** Acesso a um *workspace* com suporte a Delta Lake.
* **Bibliotecas Python:** `openpyxl`, `pandas`, `requests`, `re`, `zipfile`.
* **Ambiente Spark:** Um cluster Spark configurado para executar os comandos Python e SQL.